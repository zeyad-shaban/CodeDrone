{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "194a7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c6a7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./runs/detect/train13/weights/best_openvino_model for OpenVINO inference...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenVINO LATENCY mode for batch=1 inference on (CPU)...\n",
      "\n",
      "0: 608x608 (no detections), 370.4ms\n",
      "Speed: 0.1ms preprocess, 370.4ms inference, 6.2ms postprocess per image at shape (1, 3, 608, 608)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'sign'}\n",
       " obb: None\n",
       " orig_img: array([[[125, 134, 250],\n",
       "         [152,  33, 199],\n",
       "         [235, 103, 245],\n",
       "         ...,\n",
       "         [173, 113, 248],\n",
       "         [154,  60, 102],\n",
       "         [201,  22, 164]],\n",
       " \n",
       "        [[ 73, 138,  61],\n",
       "         [192,  45,  46],\n",
       "         [  2, 125, 143],\n",
       "         ...,\n",
       "         [179,  35, 172],\n",
       "         [ 25, 125, 134],\n",
       "         [122, 151,  15]],\n",
       " \n",
       "        [[154, 164, 109],\n",
       "         [ 93,  87, 240],\n",
       "         [237, 250, 242],\n",
       "         ...,\n",
       "         [246, 156, 155],\n",
       "         [  9, 201, 136],\n",
       "         [ 97, 121, 196]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[239, 136,  52],\n",
       "         [ 62, 143, 190],\n",
       "         [ 10, 152, 254],\n",
       "         ...,\n",
       "         [172,  10,  90],\n",
       "         [101, 110,  45],\n",
       "         [  8, 147, 165]],\n",
       " \n",
       "        [[  1,  77,  46],\n",
       "         [ 58, 145,   0],\n",
       "         [ 15,  91,  26],\n",
       "         ...,\n",
       "         [112, 225, 247],\n",
       "         [136,   2,  43],\n",
       "         [ 18,  19, 238]],\n",
       " \n",
       "        [[125, 114, 249],\n",
       "         [ 82, 209,  45],\n",
       "         [102, 156, 149],\n",
       "         ...,\n",
       "         [ 86, 120,   4],\n",
       "         [ 83, 117, 123],\n",
       "         [ 26,  73,  79]]], dtype=uint8)\n",
       " orig_shape: (608, 608)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\zeyad\\\\Desktop\\\\Projects\\\\DronePayloadDropping\\\\AIServer\\\\notebooks\\\\runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 0.10489999840501696, 'inference': 370.44840000453405, 'postprocess': 6.20280001021456}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ov_model = YOLO(\"./runs/detect/train13/weights/best_openvino_model\")\n",
    "\n",
    "dummy_frame = torch.rand(1, 3, 608, 608)\n",
    "ov_model.predict(dummy_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d258c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "vid_cap = cv2.VideoCapture(\"C:/Users/zeyad/Desktop/Projects/DronePayloadDropping/Recordings/Movie_036.mp4\")\n",
    "fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "writer = None\n",
    "out_path = \"./output.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")  # works well for .mp4\n",
    "\n",
    "\n",
    "while True:\n",
    "    curr_frame_t = time.time()\n",
    "    ret, frame = vid_cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = ov_model.predict(frame, verbose=False)\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    if writer is None:\n",
    "        h, w = annotated_frame.shape[:2]\n",
    "        writer = cv2.VideoWriter(out_path, fourcc, fps, (w, h))\n",
    "\n",
    "    cv2.imshow(\"bro\", annotated_frame)\n",
    "    \n",
    "    writer.write(annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "vid_cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "writer.release()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf86679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
